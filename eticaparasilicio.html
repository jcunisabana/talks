<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>JCES - UniSabana</title>
    <link rel="stylesheet" href="../jcunisabana.github.io/css/bootstrap.min.css">

    <link rel="stylesheet" href="css/reset.css">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/night.css">
    <!--    <link rel="stylesheet" href="css/theme/black.css">-->


    <link rel="stylesheet" href="css/estilo.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/monokai.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-74338484-2', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body>
    <div class="reveal">
        <div class="slides">

            

            <section data-background-color="white" data-background-image="img/collagesabana.jpg" data-background-size="contain" data-background-position="right">

                <div class="container">
                    <div class="row">

                        <div class="col-sm-5">
                            <h1></h1>
                            <h2 style="text-align:left; background-color:white; color:#022461" class="doscuadros">Ética para el silicio</h2> <h4 style="text-align:left; background-color:white; color:#022461" class="doscuadros"><em> Inteligencia artificial y la importancia del conocimiento</em> </h4>
                            <div style="text-align:left; background-color:white; color:#022461;">

                                <a style="color:#022461; text-decoration: underline;" href="../jcunisabana.github.io/" class="doscuadros">Juan Camilo Espejo-Serna</a>

                                <font size="4">
                                    <p class="doscuadros">Facultad de Filosofía y Ciencias Humanas</p>
                                    <p class="doscuadros" style="text-align:left; background-color:white; color:#022461; font-family:'Lucida Console', monospace">juan.espejo1@unisabana.edu.co</p>
                                </font>
                            </div>

                        </div>


                    </div>

                </div>

            </section>

            <section>El filósofo David Velleman propone la siguiente forma de pensar acerca de lo que se necesita para crear un agente moral:</section>

            <section  data-background-image="img/velleman1.png" data-background-size="contain" data-background-position="right">
                            </section>

            <section  data-background-image="img/velleman2.png" data-background-size="contain" data-background-position="right">


            </section>

            <section  data-background-image="img/velleman3.jpeg" data-background-size="contain" data-background-position="right">

                <p class="doscuadros"> Velleman habla de  "un mero sujeto de motivación" como un ser, como los animales no humanos, que supuestamente solo reacciona a las oportunidades y solicitudes del entorno, a diferencia de los seres que pueden guiar sus acciones basándose en razones morales. Si "un mero sujeto de motivación" tiene una motivación/intención/deseo de x, hace lo necesario para obtener x; no se tiene en cuenta ninguna consideración adicional. </p>
                            </section>

              <section> <h2> ¿Qué debería hacer "la gerencia media divina" para hacer que ese ser actúe según razones morales?</h2> </section>
              

             <section>
                <p class="">Quiero hablar de <span class="fragment">1) Ética deóntica para la IA, </span> <span class="fragment"> y 2) Una ética de virtudes para la IA </span></p>

                
            </section>               


            <section data-background-color="white" data-background-image="img/collagesabana.jpg" data-background-size="contain" data-background-position="right">

                <h3 class="doscuadros" style="color:#022461"> Ética deóntica para la IA</h3>
</section>


            <section> Según Velleman, no se tiene que empezar desde cero a la hora de diseñar una criatura con razonamiento práctico; se debe construir a partir de lo que ya está presente e introducir "un mecanismo que modifique las fuerzas motivacionales que ya están en funcionamiento". El razonamiento ético, así, interviene en los resortes de acción ya existentes. Dicha intervención consiste en bloquear o inhibir ciertos comportamientos y fortalecer y ayudar a otros. </section>

<section>Este justamente es el caso de los modelos matemáticos de decisión usados contemporáneamente en la variedad de tecnologías que podemos agrupar bajo el nombre de IA. <div class="fragment"> Nos encontramos en una situación razonablemente parecida en la medida en que tenemos "sujetos motivacionales" de los que estamos buscando principios generales que inhiban o fortalezcan conductas.  Estos principios pueden tener la forma de <span class="fragment"> políticas públicas,</span> <span class="fragment"> leyes,</span> <span class="fragment"> lineamientos</span> <span class="fragment"> o marcos para la IA que se deben aplicar a dichas tecnologías.</span> </div></section>

            <section data-background-image="img/marcoeticocol.png" data-background-size="contain" data-background-position="right">

<p class="doscuadros">Por ejemplo: cerca del final del gobierno Duque, se diseñó un marco ético para la IA en Colombia que  busca  

«brindar una “guía de soft law” de recomendaciones y sugerencias a las Entidades Públicas, para abordar la formulación y gestión de los proyectos que incluyan el uso de Inteligencia Artificial (IA).» </p>
             </section>

<section data-background-image="img/marcoeticocol.png" data-background-size="contain" data-background-position="right">

<p class="doscuadros">

Entre estos principios, podemos encontrar la transparencia, la explicabilidad, condiciones de Human-in-the-loop, seguridad, responsabilidad, no discriminación, inclusión, prevalencia de los derechos de niños, niñas y adolescentes, beneficio social, etc.

</p>
             </section>


<section data-background-image="img/algobias.jpg" data-background-size="contain" data-background-position="right">

<div class="doscuadros highlightred ">
<p> 
Concentrémonos en la no-discriminación, por poner un principio que ha sido bastante revisado. (Véase <em>Armas de destrucción matemática</em> de Cathy O'Neil como un ejemplo de una buena presentación en español de varios tipos de sesgos de los que hablo.)


</p>
</div>
             </section>

 <section data-background-image="img/algobias.jpg" data-background-size="contain" data-background-position="right">

<div class="doscuadros highlightred ">
<p> 

¿Cómo hacer que ese principio de no discriminación se cumpla? Es decir,  ¿cómo determinar qué comportamientos se deben bloquear o inhibir? ¿qué se debe fortalecer y ayudar ?

</p>
</div>
             </section>            
<section >

<p>
Suresh y Guttag (2019) proporcionan una buena primera clasificación de los diferentes tipos de sesgo y discriminación introducidos en diferentes etapas del ciclo de desarrollo de la IA.


</p>

             </section>

<section data-background-image="img/sureshyguttag.png" data-background-size="contain" data-background-position="right">


<div class="doscuadros fragment highlightred" >

¿Dónde intervendría la <br> no-discriminación?

</div>
             </section>
 <section data-background-image="img/algobias.jpg" data-background-size="contain" data-background-position="right">

<div class="doscuadros highlightred">

¿Qué hacemos ante estas posibles injusticias?

</div>
<div class=" doscuadros">

<div class="highlightred fragment"> De acuerdo con la sugerencia deontológica de la que habla Velleman, el lugar los principios como los del marco ético será el momento de la implementación o quizá al nivel del modelo de salida (Model output) en donde quizá se inhiban las conductas que refuercen un sesgos y refuercen ciertas conductas que deshagan sesgos.</div>
</div>
             </section>
 <section data-background-image="img/algobias.jpg" data-background-size="contain" data-background-position="right">




<p class="doscuadros highlightred">Cada infeliz injusticia lo es a su manera; no viene en talla única. <span class="fragment">Además la evidencia empírica sugiere de que no hay un set de principios que sirva para todos los casos. (Véase Mehrabi et al. (2019) para un  listado de intentos de soluciones.) </span></p>
             </section>

<section data-background-color="white" data-background-image="img/collagesabana.jpg" data-background-size="contain" data-background-position="right">

                <h3 class="doscuadros" style="color:#022461">Una ética de virtudes para la IA</h3>
</section>

<section>Uno podría pensar: dado que los estados motivacionales y la justicia son partes de la acción no discriminativa, solo es cuestión de identificar qué se necesita adicionar para juntarlo todo. <span class="fragment"> Es cuestión de dar con el principio preciso, el marco perfecto para adicionar a la mezcla. 


</span> 

<p class="fragment">Pero es evidente que todavía no se ha logrado.</p>
</section>

<section>Una explicación del fracaso: la idea de AGREGAR se basa en una comprensión infundada de la relación entre las partes y el todo. Una idea quizá fortalecida por la tradición analítica de comienzos del siglo XX pero muy propia de la visión una ética deontológica de principios, reglas y lineamientos.</span>


<p class="fragment"> Tim Williamson es un fiero crítico de estas aproximaciones "agregadoras" en filosofía y nos puede ayudar en este diagnóstico por medio del siguiente ejemplo.</p> </section>

<section  data-background-image="img/pelotaroja.jpg" data-background-size="contain" data-background-position="right">
    

    <p class="doscuadros">
   Cuando decimos de una pelota que es roja, en contraposición a ser azul, verde o violeta, y que es de plástico, en contraposición a ser de tela o cuero, hablamos de dos propiedades distintas e independientes de la pelota. Ser de plástico y ser roja no tienen nada qué ver en el caso de esta pelota.</p>


</section>


<section  data-background-image="img/pelotaroja.jpg" data-background-size="contain" data-background-position="right">
    

    <p class="doscuadros">
Pero cuando decimos de una pelota que es roja, en oposición a otras formas de tener un color, y que está coloreada, en oposición a ser transparente, no estamos hablando de dos propiedades distintas e independientes de la pelota. </p>


</section>

<section  data-background-image="img/pelotaroja.jpg" data-background-size="contain" data-background-position="right">
    

    <p class="doscuadros">
<em>Ser roja y ser coloreada no son independientes</em>. <br> Ser roja es una manera determinada de estar coloreada. La pelota no es roja e independientemente de esta propiedad también tiene la propiedad de estar coloreada. El ser rojo, azul o verde simplemente son diferentes maneras de estar coloreado.</p>


</section>


<section  data-background-image="img/williamson.jpg" data-background-size="contain" data-background-position="right">
    

    <p class="doscuadros">
En palabras de Williamson: Es intentar resolver esta ecuación en la variable 'Z': <br> rojo = coloreado + Z. ... </p>


</section>

<section  data-background-image="img/williamson.jpg" data-background-size="contain" data-background-position="right">
    

    <p class="doscuadros">
"Pero, ¿qué podría ser Z? Se obtiene una ecuación casi trivialmente verdadera al sustituir 'rojo' mismo por 'Z', o 'rojo, si es coloreado', pero eso violaría la restricción habitual de no-circularidad. Incluso si ser rojo se puede reducir a una propiedad especificada en términos físicos, eso no encajaría en el patrón mostrado, ya que carecería de 'coloreado' como componente ...
</p>


</section>


<section  data-background-image="img/williamson.jpg" data-background-size="contain" data-background-position="right">
    

    <p class="doscuadros">
La moraleja es: no asuma que una condición necesaria para algo es un componente de una definición o análisis no circular de esa cosa." (Williamson 2017: 173)
</p>


</section>

<section >
    

    <p class="">
Pregunta: ¿Qué correspondería al intento de resolver esta ecuación en la variable 'Z': <br> decisión no-discriminativa = decisión motivada + Z?</p>

</p>

<p class="fragment">
Respuesta: Nada. 

<br> No encontramos el principio preciso, el marco perfecto para adicionar a la mezcla.
</p>


</section>

<section>
    
<h1>¿Entonces?</h1>    
</section>

<section  data-background-image="img/murdoch.jpg" data-background-size="contain" data-background-position="right">
    
<p class="doscuadros highlightred">

Esto resuena con una idea de Iris Murdoch. 

<span class="fragment"> 

Para Murdoch, la moralidad es cuestión de ver de manera "justa y amorosa" ("<em>justly and lovingly</em>"); no tanto de elección, ni de la voluntad, ni de la acción. </span>
</p>

</section>

<section  data-background-image="img/murdoch.jpg" data-background-size="contain" data-background-position="right">
    
<p class="doscuadros highlightred">

"Simone Weil said that morality was a matter of attention, not of will" (Murdoch, <em>Against Dryness</em>)
</p>

<p class="doscuadros highlightred">
“What M is ex hypothesi attempting to do is not just to see D accurately but to see her justly or lovingly. Notice the rather different image of freedom which this at once suggests. Freedom is not the sudden jumping of the isolated will in and out of an impersonal logical complex, it is a function of the progressive attempt to see a particular object clearly.” (Murdoch, <em>The Sovereignty of Good</em>)


</p>



</section>

<section  data-background-image="img/murdoch.jpg" data-background-size="contain" data-background-position="right">
    
<p class="doscuadros highlightred">

No me voy a meter en el detalle de la caracterización positiva de Murdoch. Pero creo que hay algo interesante en la idea general: 
</p>

<p class="doscuadros highlightred fragment">La moralidad no es cuestión de finales como las acciones, sino de los comienzos. </p>

</section>

<section>
    
No es cuestión de inhibir y reforzar, como sugiere Velleman. No se trata de encontrar el Z qué agregar. No se resuelven al final. 

<p class="fragment"> 
El resultado de la deliberación moral, según Murdoch, es un nuevo comienzo. La suegra M del ejemplo de Murdoch atiende de manera amorosa a D; no está inhibiendo nada. Hay una intento constante de ir mejorando la manera en que la ve.  
</p>
</section>


<section>
El punto de Murdoch es que la actividad moral no sólo se ve en la acción o en la decisión en la que <em>terminamos</em> sino que el razonamiento práctico también se encuentra en la manera en que <em>partimos</em>.

</section>

<section>
Esto sugiere una etica de las virtudes para toda esta variedad de tecnologías que podemos agrupar bajo el nombre de IA con el fin de ponerse en el "intento progresivo de ver claramente un objeto particular" del que habla Murdoch.

<p class="fragment">Pero además me interesa resaltar la importancia del conocimiento como un ideal al que apuntar.  </p>

</section>


<section  data-background-image="img/vallor.jpeg" data-background-size="contain" data-background-position="right">

<div class="doscuadros">
    <p>
Ya la relación entre IA y ética de virtudes se ha realizado (ej. Shannon Vallor 2016) 

</p>
<p class="fragment">pero me interesa ver cómo es que las cuestiones sobre la naturaleza del conocimiento se pueden integrar en la filosofía de la IA. 
</p>
</div>
</section>

<section>La idea de que la IA require conocimiento se remonta a los orígenes a finales del siglo XX.
                <p>Edward Feigenbaum (1983) sugirió que la solución de problemas de manera alto nivel (problemas que requieren de inteligencia) depende <b>menos</b> de la sofisticación del agente cognitivo y más de que éste tuviese el conocimiento especialista apropiado.
                </p>


</section>

  <section>
                <p>De la idea de Feignbaum nace una rama de la investigación en inteligencia artificial que busca encontrar la mejor manera de representar conocimiento y construir sistemas expertos artificiales.</p>

                En su momento, la posiblidad de llegar a inteligencia artificial por medio de sistemas expertos encontró muchos problemas (famosamente, el problema del marco) pues no es fácil determinar qué conocimiento es relevante para una tarea determinada. <br> 

<br>
                Ahora, sin embargo, los macrodatos están "solucionando" el problema. 

</section>

<section>Me interesa la idea de que la soluciones a problemas compejos para una IA depende del conocimiento, como señalaba Murdoch.</section>

<section>

<p class="">
                     Sin embargo en el contexto de la IA y la psicología computacional, la forma en que se habla de 'conocimiento' es bien diferente de la forma en que se habla de conocimiento en epistemología; es menos estricta. 

<br> 
                1. conocimiento = datos; 
                <br> 2. conocimiento = un ideal de un estado cognitivo al que se debe apuntar</p>

</section>


<section>
Debemos integrar los estudios de la epistemología sobre la naturaleza del conocimiento a la IA como un ideal de un estado cognitivo al que se debe apuntar.

<p class="fragment"> Pero una aclaración las implicaciones ya tendrá que darse en la sección de preguntas o con cerveza. </p>   

</section>



            <section data-background-color="white" data-background-image="img/collagesabana.jpg" data-background-size="contain" data-background-position="right">
                <div class="container">
                    <div class="row">
                        <div class=" col-sm-5">
                            <h1 class="doscuadros" style="text-align:left; background-color:white; color:#022461">
                                ¡Gracias!</h1>
                                <div style="text-align:left; background-color:white; color:#022461;">

                                <a style="color:#022461; text-decoration: underline;" href="../jcunisabana.github.io/" class="doscuadros">Juan Camilo Espejo-Serna</a>

                                <font size="4">
                                    <p class="doscuadros">Facultad de Filosofía y Ciencias Humanas</p>
                                    <p class="doscuadros" style="text-align:left; background-color:white; color:#022461; font-family:'Lucida Console', monospace">juan.espejo1@unisabana.edu.co</p>
                                </font>
                            </div>

                        </div>
                    </div>
                </div>
            </section>



        </div>
    </div>

    <script src="js/reveal.js"></script>

    <script>
        // More info about config & dependencies:
        // - https://github.com/hakimel/reveal.js#configuration
        // - https://github.com/hakimel/reveal.js#dependencies
        Reveal.initialize({
            slideNumber: true,
            fragmentInURL: false,
            autoPlayMedia: true,
            totalTime: 2800, // 12600= 3.5 horas. 14400=4 horas. total de tiempo para la totalidad de la presentación
            hash: true,
            dependencies: [{
                    src: 'plugin/markdown/marked.js'
                },
                {
                    src: 'plugin/markdown/markdown.js'
                },
                {
                    src: 'plugin/highlight/highlight.js'
                },
                {
                    src: 'plugin/notes/notes.js',
                    async: true
                }
            ]
        });
    </script>
</body>

</html>
